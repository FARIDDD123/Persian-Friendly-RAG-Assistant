# app.py
import streamlit as st
import os
import tempfile
from PyPDF2 import PdfReader
from langdetect import detect
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter

# Set your OpenAI API key here or through secrets/environment
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-openai-api-key")

# UI setup
st.set_page_config(page_title="Persian Research Assistant", layout="wide")
st.title("ğŸ§  Ø¯Ø³ØªÛŒØ§Ø± ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ")

uploaded_file = st.file_uploader("ğŸ“„ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ PDF Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", type=["pdf"])
user_query = st.text_input("â“ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ù†Ù…Ø§ÛŒÛŒØ¯:")

# Helper function to extract text
def extract_text_from_pdf(file):
    reader = PdfReader(file)
    return "".join(page.extract_text() or "" for page in reader.pages)

# Language detection
def detect_language(text):
    try:
        return detect(text)
    except Exception:
        return "unknown"

# Main logic
if uploaded_file and user_query:
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_file_path = tmp_file.name

    text = extract_text_from_pdf(tmp_file_path)
    lang = detect_language(text)
    st.info(f"Ø²Ø¨Ø§Ù† Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡: {'ÙØ§Ø±Ø³ÛŒ' if lang == 'fa' else lang}")

    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = splitter.split_text(text)

    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    vectorstore = Chroma.from_texts(texts, embedding=embeddings)

    prompt = user_query if lang != 'fa' else f"Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø¹Ù„Ù…ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¨Ø¯Ù‡: {user_query}"

    llm = OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0.3)
    qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

    response = qa.run(prompt)

    st.subheader("âœï¸ Ù¾Ø§Ø³Ø® Ø¯Ø³ØªÛŒØ§Ø±:")
    st.write(response)

